# Note: RESULTS_2 is same results as run by Mirko, but
# at the current time is less up to date.
# The suffixes on the "wer" numbers are the inverses of the acoustic
# scales.  Here, we show the best number on each test set.
# [really, these scales should be tuned on a dev set, but we think it's
# fine to compare the WERs obtained this way to each other.]

  for x in exp/*/decode*; do [ -d $x ] && grep WER $x/wer_* | utils/best_wer.sh; done

# monophone, deltas, half of SI-84
exp/mono0a/decode_tgpr_dev93/wer_11:%WER 34.30 [ 2824 / 8234, 243 ins, 511 del, 2070 sub ]
exp/mono0a/decode_tgpr_eval92/wer_9:%WER 24.90 [ 1405 / 5643, 148 ins, 191 del, 1066 sub ]

# triphone, deltas, half of SI-84
exp/tri1/decode_tgpr_dev93/wer_15:%WER 19.59 [ 1613 / 8234, 259 ins, 196 del, 1158 sub ]

# triphone, deltas, SI-84
exp/tri2a/decode_tgpr_dev93/wer_15:%WER 17.69 [ 1457 / 8234, 262 ins, 160 del, 1035 sub ]

# triphone, LDA+MLLT, SI-84
exp/tri2b/decode_tgpr_dev93_fromlats/wer_15:%WER 16.71 [ 1376 / 8234, 267 ins, 139 del, 970 sub ]
exp/tri2b/decode_tgpr_dev93_tg/wer_16:%WER 16.26 [ 1339 / 8234, 267 ins, 141 del, 931 sub ]
exp/tri2b/decode_tgpr_dev93_tg_biglm/wer_16:%WER 16.42 [ 1352 / 8234, 269 ins, 142 del, 941 sub ]

exp/tri2b/decode_tgpr_eval92/wer_17:%WER 11.45 [ 646 / 5643, 140 ins, 46 del, 460 sub ]

# +MMI
exp/tri2b_mmi/decode_tgpr_eval92/wer_14:%WER 10.63 [ 600 / 5643, 124 ins, 45 del, 431 sub ]
#  +boosting
exp/tri2b_mmi_b0.1/decode_tgpr_eval92/wer_16:%WER 10.69 [ 603 / 5643, 119 ins, 48 del, 436 sub ]
# +fMMI
exp/tri2b_fmmi_b0.1/decode_tgpr_eval92/wer_15:%WER 10.26 [ 579 / 5643, 111 ins, 39 del, 429 sub ]

# +MCE
exp/tri2b_mce/decode_tgpr_eval92/wer_16:%WER 11.15 [ 629 / 5643, 132 ins, 45 del, 452 sub ]

# LDA+ET, SI-84 [note: this is speaker adaptive, so better to compare with SAT numbers
# which would be better than this when adapting on entire speaker]
exp/tri2c/decode_tgpr_dev93/wer_15:%WER 16.60 [ 1367 / 8234, 267 ins, 137 del, 963 sub ]
exp/tri2c/decode_tgpr_dev93_2pass/wer_15:%WER 16.24 [ 1337 / 8234, 253 ins, 140 del, 944 sub ]



# LDA+MLLT+SAT, SI-84
exp/tri3b/decode_tgpr_dev93/wer_16:%WER 14.49 [ 1193 / 8234, 243 ins, 108 del, 842 sub ]
exp/tri3b/decode_tgpr_dev93_tg/wer_16:%WER 13.75 [ 1132 / 8234, 252 ins, 97 del, 783 sub ]

exp/tri3b/decode_tgpr_eval92/wer_15:%WER 9.85 [ 556 / 5643, 139 ins, 36 del, 381 sub ]
exp/tri3b/decode_tgpr_eval92_tg/wer_16:%WER 9.07 [ 512 / 5643, 130 ins, 32 del, 350 sub ]
 # same with big-dict, on eval'92
 exp/tri3b/decode_bd_tgpr_eval92/wer_16:%WER 7.60 [ 429 / 5643, 59 ins, 51 del, 319 sub ]
 exp/tri3b/decode_bd_tgpr_eval92_fg/wer_16:%WER 6.26 [ 353 / 5643, 52 ins, 40 del, 261 sub ]
 exp/tri3b/decode_bd_tgpr_eval92_tg/wer_16:%WER 6.49 [ 366 / 5643, 55 ins, 39 del, 272 sub ]

 # note: mixing up from 15k->20k Gaussians, it's a bit better [14.66->14.26]
 exp/tri3b_20k/decode_tgpr_dev93/wer_16:%WER 14.22 [ 1171 / 8234, 243 ins, 105 del, 823 sub ]

 # Note: the numbers below are the same experiments as the few lines above, but run a 
 # different time on a different type of amachine so they differ slightly (need to run
 # all this on one machine).  They show
 # the effect of a small RNNLM with just 30 hidden layers.  WER changes from 6.43 to 6.01
 # when we add in RNNLM with weight 0.25.  We only tried weights of 1 and 0.25.  
 exp/tri3b/decode_bd_tgpr_eval92/wer_16:%WER 7.53 [ 425 / 5643, 61 ins, 47 del, 317 sub ]
 exp/tri3b/decode_bd_tgpr_eval92_fg/wer_17:%WER 6.43 [ 363 / 5643, 55 ins, 44 del, 264 sub ]
 exp/tri3b/decode_bd_tgpr_eval92_fg_rnnlm/wer_19:%WER 6.63 [ 374 / 5643, 62 ins, 38 del, 274 sub ]
 exp/tri3b/decode_bd_tgpr_eval92_fg_rnnlm_0.25/wer_18:%WER 6.01 [ 339 / 5643, 53 ins, 39 del, 247 sub ]
 exp/tri3b/decode_bd_tgpr_eval92_tg/wer_18:%WER 6.80 [ 384 / 5643, 58 ins, 46 del, 280 sub ]




# sgmm3c is SGMM on top of LDA+MLLT.
# In this case decoding from lattices is worse, presumably because the lattices used
# (tri2b) had a bad WER (17.78%).
exp/sgmm3c/decode_tgpr_dev93/wer_16:%WER 13.74 [ 1131 / 8234, 188 ins, 131 del, 812 sub ]
exp/sgmm3c/decode_tgpr_dev93_fromlats/wer_13:%WER 15.16 [ 1248 / 8234, 262 ins, 113 del, 873 sub ]
# faster decoding via more aggressive Gaussian selection in 1st pass [15->3];
#  speed goes from ~1.1xRT -> ~0.8xRT
exp/sgmm3c/decode_tgpr_dev93_gs3/wer_16:%WER 13.66 [ 1125 / 8234, 186 ins, 133 del, 806 sub ]

## HERE [redoing results]

# LDA+MLLT+SAT, SI-284, quick retraining from 3b
exp/tri4b/decode_tgpr_dev93/wer_13:%WER 12.53 [ 1032 / 8234, 242 ins, 79 del, 711 sub ]
exp/tri4b/decode_tgpr_eval92/wer_16:%WER 8.05 [ 454 / 5643, 119 ins, 23 del, 312 sub ]

# +MMI
exp/tri4b_mmi/decode_tgpr_dev93/wer_12:%WER 11.28 [ 929 / 8234, 206 ins, 76 del, 647 sub ]
#+boosting
exp/tri4b_mmi_b0.1/decode_tgpr_dev93/wer_16:%WER 11.25 [ 926 / 8234, 176 ins, 94 del, 656 sub ]
 # increasing beam from 13 to 15 to see effect. 
 exp/tri4b_mmi_b0.1/decode_tgpr_dev93_b15/wer_14:%WER 10.72 [ 883 / 8234, 172 ins, 84 del, 627 sub ]
exp/tri4b_mmi_b0.1/decode_tgpr_eval92/wer_14:%WER 7.34 [ 414 / 5643, 105 ins, 20 del, 289 sub ]

#+fMMI
exp/tri4b_fmmi_b0.1/decode_tgpr_dev93/wer_13:%WER 10.86 [ 894 / 8234, 167 ins, 89 del, 638 sub ]
exp/tri4b_fmmi_b0.1/decode_tgpr_eval92/wer_12:%WER 7.25 [ 409 / 5643, 111 ins, 14 del, 284 sub ]


# LDA+MLLT+SAT, SI-284, full retraining starting from 3b [c.f. 4b]
exp/tri4c/decode_tgpr_dev93/wer_16:%WER 12.10 [ 996 / 8234, 220 ins, 83 del, 693 sub ]
 # Mixing up further:
 exp/tri4c_100k/decode_tgpr_dev93/wer_15:%WER 11.65 [ 959 / 8234, 222 ins, 75 del, 662 sub ]
 exp/tri4c_50k/decode_tgpr_dev93/wer_16:%WER 12.21 [ 1005 / 8234, 229 ins, 87 del, 689 sub ]
 exp/tri4c_75k/decode_tgpr_dev93/wer_16:%WER 12.00 [ 988 / 8234, 221 ins, 79 del, 688 sub ]

# sgmm4b is LDA+MLLT+SAT, on just SI-84 data.
exp/sgmm4b/decode_tgpr_dev93/wer_12:%WER 12.45 [ 1025 / 8234, 207 ins, 98 del, 720 sub ]
exp/sgmm4b/decode_tgpr_eval92/wer_13:%WER 8.38 [ 473 / 5643, 117 ins, 24 del, 332 sub ]
 # mixing up a bit more:
 exp/sgmm4b_12500/decode_tgpr_eval92/wer_14:%WER 8.36 [ 472 / 5643, 112 ins, 22 del, 338 sub ]
 # increasing subspace dim to 50.
 exp/sgmm4b_50/decode_tgpr_eval92/wer_13:%WER 8.20 [ 463 / 5643, 119 ins, 26 del, 318 sub ]


# sgmm4c is the same, but on all SI-284 data.
exp/sgmm4c/decode_tgpr_dev93/wer_12:%WER 10.55 [ 869 / 8234, 167 ins, 82 del, 620 sub ]
exp/sgmm4c/decode_tgpr_eval92/wer_18:%WER 7.53 [ 425 / 5643, 96 ins, 23 del, 306 sub ]

# rescoring with full trigram LM.
exp/sgmm4c/decode_tgpr_dev93_tg/wer_13:%WER 9.96 [ 820 / 8234, 167 ins, 84 del, 569 sub ]
exp/sgmm4c/decode_tgpr_eval92_tg/wer_11:%WER 7.09 [ 400 / 5643, 110 ins, 15 del, 275 sub ]

 # using big-dict.
 exp/sgmm4c/decode_bd_tgpr_eval92/wer_12:%WER 4.86 [ 274 / 5643, 41 ins, 18 del, 215 sub ]
 exp/sgmm4c/decode_bd_tgpr_eval92_gs3/wer_12:%WER 4.87 [ 275 / 5643, 41 ins, 18 del, 216 sub ] [faster decoding, ~1.3xRT -> 0.6xRT]
 exp/sgmm4c/decode_bd_tgpr_eval92_tg/wer_12:%WER 4.59 [ 259 / 5643, 36 ins, 22 del, 201 sub ]
 exp/sgmm4c/decode_bd_tgpr_eval92_fg/wer_15:%WER 4.24 [ 239 / 5643, 29 ins, 25 del, 185 sub ]

 # Decoding via lattice rescoring of lats from tri3b [c.f. 4.24 above]... quite a bit worse.
 exp/sgmm4c/decode_bd_fg_eval92_fromlats/wer_17:%WER 5.35 [ 302 / 5643, 51 ins, 27 del, 224 sub ]

# sgmm4d is as sgmm4c, but quinphone, not triphone.  Decoding only via lattice rescoring
# (not sure if graph compilation will blow up).
#   Rescoring tri3b lattices (c.f. exp/sgmm4c/decode_bd_fg_eval92_fromlats, which is 5.35% WER)
exp/sgmm4d/decode_bd_fg_eval92_fromlats/wer_14:%WER 5.19 [ 293 / 5643, 51 ins, 24 del, 218 sub ]

# rescoring lattices from sgmm4c.  Baseline is probably exp/sgmm4c/decode_bd_tgpr_eval92_fg/,
# which is 4.24%.
exp/sgmm4d/decode_bd_fg_eval92_fromlats2/wer_18:%WER 4.22 [ 238 / 5643, 25 ins, 27 del, 186 sub ]
